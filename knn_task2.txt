import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder

#data
data = {

    'Weight': [51, 62, 69, 64, 65, 56, 58, 57, 55],

    'Height': [167, 182, 176, 173, 172, 174, 169, 173, 170],

    'Class': ['Underweight', 'Normal', 'Normal', 'Normal', 'Normal', 'Underweight', 'Normal', 'Normal', 'Normal']

}
df = pd.DataFrame(data)
le = LabelEncoder()

df['Class'] = le.fit_transform(df['Class'])  # Underweight = 1, Normal = 0

# Feature & target

X = df[['Weight', 'Height']]

y = df['Class']


# Finding the best K using cross-validation

k_values = range(1, 10)

accuracy_scores = []



for k in k_values:
    model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')

    scores = cross_val_score(model, X, y, cv=5)  # 5-Fold Cross Validation

    accuracy_scores.append(scores.mean())



# Plot the results

plt.plot(k_values, accuracy_scores, marker='o')

plt.xlabel('K Value')

plt.ylabel('Cross-Validation Accuracy')

plt.title('Elbow Method for Optimal K')

plt.show()